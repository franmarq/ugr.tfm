ThetaMC <- ThetaMC + g/n
}
ThetaMC
# Limpiar el espacio de trabajo
rm(list = ls())
# Establecer el tamaño de la muestra y el estimador inicial
n <- 50
ThetaAnt <- 0
# Generar variables antitéticas
x <- runif(n)
# Realizar el bucle para calcular el estimador de Monte Carlo con variables antitéticas
for (i in 1:n) {
# Calcular la muestra original y la muestra antitética
MuestraO <- (2 * x[i] - 1) * 2
MuestraAnt <- (2 * (1 - x[i]) - 1) * 2
# Calcular las funciones de peso para cada muestra
gO <- 1 / (pi * (1 + MuestraO^2))
gAnt <- 1 / (pi * (1 + MuestraAnt^2))
# Promediar los valores de las dos funciones de peso
ThetaAnt <- ThetaAnt + (gO + gAnt) / 2 / n
}
# Imprimir el resultado del estimador
cat("Estimador con variables antitéticas:", ThetaAnt, "\n")
# Gráfico de densidad de probabilidad
a <- -4
b <- 4
x <- seq(a, b, length = 100)
y <- dnorm(x, mean = 0, sd = sqrt(1/pi))
plot(x, y, type = "l", lwd = 2, col = "blue",
xlab = "x", ylab = "Densidad de probabilidad",
main = "Distribución Normalizada de Muestras Antitéticas")
# Imprimir el resultado del estimador
cat("Estimador con variables antitéticas:", ThetaMC, "\n")
n <- 1000
b <- 2
a <- -2
LI <- b-a
ThetaMC <- 0
x <- runif(n, min = 0, max = 1)
for (I in 1:n) {
Muestra <- (2 * x[I] - 1) * 2
g <- LI / (pi * (1 + Muestra^2))
ThetaMC <- ThetaMC + g/n
}
# Imprimir el resultado del estimador
cat("Estimador con variables antitéticas:", ThetaMC, "\n")
# Imprimir el resultado del estimador
cat("Estimador del parámetro:", ThetaMC, "\n")
#3.antiteticas
# Limpiar el espacio de trabajo
rm(list = ls())
# Establecer el tamaño de la muestra y el estimador inicial
n <- 50
ThetaAnt <- 0
# Generar variables antitéticas
x <- runif(n)
# Realizar el bucle para calcular el estimador de Monte Carlo con variables antitéticas
for (i in 1:n) {
# Calcular la muestra original y la muestra antitética
MuestraO <- (2 * x[i] - 1) * 2
MuestraAnt <- (2 * (1 - x[i]) - 1) * 2
# Calcular las funciones de peso para cada muestra
gO <- 1 / (pi * (1 + MuestraO^2))
gAnt <- 1 / (pi * (1 + MuestraAnt^2))
# Promediar los valores de las dos funciones de peso
ThetaAnt <- ThetaAnt + (gO + gAnt) / 2 / n
}
# Imprimir el resultado del estimador
cat("Estimador con variables antitéticas:", ThetaAnt, "\n")
rm(list = ls())
#4. Variables de control
set.seed(123) # establecer semilla para reproducibilidad
n <- 50
Cstar <- 0.2956
v <- runif(n)
u <- runif(n)
Theta <- 0
for (i in 1:n) {
ThetaC <- 0
Mu <- pi*(v[i]-0.5)
Muestra <- tan(Mu)
if (Muestra >= 2) {
g <- 1
} else {
g <- 0
}
if (u[i] <= 1/2) {
Y <- 1
} else {
Y <- 0
}
Theta <- Theta + g/n + Cstar*(Y-1/2)/n
}
Theta # valor del estimador
set.seed(123)
n <- 16
x <- rcauchy(n,1,0)
g <- function(x) {ifelse(x >= 2, 1/(pi*(1+x^2)), 0)}
theta_hat <- mean(g(x))
var_hat <- (1/n) * (sum(g(x)^2) - (theta_hat)^2)
cat("La estimación de Theta es:", theta_hat, "\n")
cat("La estimación de la varianza del estimador es:", var_hat, "\n")
rm(list = ls())
set.seed(123)
n <- 16
x <- rcauchy(n,1,0)
g <- function(x) {ifelse(x >= 2, 1/(pi*(1+x^2)), 0)}
theta_hat <- mean(g(x))
var_hat <- (1/n) * (sum(g(x)^2) - (theta_hat)^2)
cat("La estimación de Theta es:", theta_hat, "\n")
cat("La estimación de la varianza del estimador es:", var_hat, "\n")
rm(list = ls())
set.seed(123)
n <- 160
x <- rcauchy(n,1,0)
g <- function(x) {ifelse(x >= 2, 1/(pi*(1+x^2)), 0)}
theta_hat <- mean(g(x))
var_hat <- (1/n) * (sum(g(x)^2) - (theta_hat)^2)
cat("La estimación de Theta es:", theta_hat, "\n")
cat("La estimación de la varianza del estimador es:", var_hat, "\n")
rm(list = ls())
set.seed(123)
n <- 1600
x <- rcauchy(n,1,0)
g <- function(x) {ifelse(x >= 2, 1/(pi*(1+x^2)), 0)}
theta_hat <- mean(g(x))
var_hat <- (1/n) * (sum(g(x)^2) - (theta_hat)^2)
cat("La estimación de Theta es:", theta_hat, "\n")
cat("La estimación de la varianza del estimador es:", var_hat, "\n")
rm(list = ls())
set.seed(123)
n <- 16000
x <- rcauchy(n,1,0)
g <- function(x) {ifelse(x >= 2, 1/(pi*(1+x^2)), 0)}
theta_hat <- mean(g(x))
var_hat <- (1/n) * (sum(g(x)^2) - (theta_hat)^2)
cat("La estimación de Theta es:", theta_hat, "\n")
cat("La estimación de la varianza del estimador es:", var_hat, "\n")
rm(list = ls())
set.seed(123) # fijar semilla para reproducibilidad
n <- 16
alpha <- 1
beta <- 0
x <- rcauchy(n, alpha, beta)
g <- function(x) 1/(pi*(1+x^2))
theta_MC <- mean(g(x))*(b-a)
rm(list = ls())
set.seed(123) # fijar semilla para reproducibilidad
n <- 16
alpha <- 1
beta <- 0
b=10
x <- rcauchy(n, alpha, beta)
g <- function(x) 1/(pi*(1+x^2))
theta_MC <- mean(g(x))*(b-a)
rm(list = ls())
set.seed(123)  # Fijamos la semilla para reproducibilidad
n <- 16  # Tamaño de la muestra
x <- rcauchy(n, 1, 0)  # Generamos la muestra de Cauchy
theta_hat <- mean(1/(pi*(1+x^2)))  # Calculamos el estimador de theta
# Calculamos la varianza del estimador
var_hat <- var(1/(pi*(1+x^2)))
mse <- var_hat/n  # Estimamos la varianza del estimador
var_hat
mse
rm(list = ls())
set.seed(123)
n <- 16
x <- rcauchy(n,1,0)
g <- function(x) {ifelse(x >= 2, 1/(pi*(1+x^2)), 0)}
theta_hat <- mean(g(x))
var_hat <- (1/n) * (sum(g(x)^2) - (theta_hat)^2)
cat("La estimación de Theta es:", theta_hat, "\n")
cat("La estimación de la varianza del estimador es:", var_hat, "\n")
rm(list = ls())
set.seed(123)  # Fijamos la semilla para reproducibilidad
n <- 16  # Tamaño de la muestra
u <- runif(n, -1, 1)  # Generamos la muestra de valores uniformes
theta_hat <- (2/n)*sum(abs(u)*exp(u^2))  # Calculamos el estimador de theta
theta_hat
cat("La estimación de Theta es:", theta_hat, "\n")
knitr::opts_chunk$set(echo = TRUE)
datos <- read.csv("Temperaturas365.csv", header = TRUE)
setwd ('C:\Users\franm\OneDrive\Documents\Personales\Javier\Academicos\UGR - Estadistica Aplicada\Materias\22-23\Analisis de Datos Funcionales\Tema 5')
getwd
?getwd
setwd (C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/22-23/Analisis de Datos Funcionales/Tema 5)
setwd ("C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/22-23/Analisis de Datos Funcionales/Tema 5")
datos <- read.csv("Temperaturas365.csv", header = TRUE)
getwd()
datos <- read.csv("Temperaturas365.csv", header = TRUE)
datos <- read.csv("Temperaturas365.csv", header = TRUE)
install.packages("installr")
library(installr)
updateR()
# Caso 1. Serie de tiempo por Muestreo
#Lectura de los datos
setwd("C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/22-23/C2 Análisis de Series Temporales/Actividad Tema 1/")
# definicion del origen
archivo <- c("datos/Gasoline_Retail_Prices_Weekly.csv")
#lectura del archivo origen
df = read.csv(archivo, header=TRUE)
head(df)
colnames(df)
names(df) <- c("date", "gasprice")
names(df)
#cambio de formato fecha para la variable test.date
df$date <- as.Date(df$date,format="%m/%d/%Y")
class(df$date)
# Caso 2. Serie de tiempo por agregación
# definicion del origen
archivo2 <- c("datos/LinkNYC_Weekly_Users.csv")
#lectura del archivo origen
df2 = read.csv(archivo2, header=TRUE)
head(df2)
colnames(df2)
names(df2) <- c("date", "users")
names(df2)
#cambio de formato fecha para la variable test.date
df2$date <- as.Date(df2$date,format="%m/%d/%Y")
class(df2$date)
X <- df[,2]
head(X)
Y <- df2[,2]
str(X)
str(Y)
library(ggplot2)
library(ggplot2)
install.packages("ggplot2")
q()
getwd()
car_name <-c("Honda","BMW","Ferrari")
car_name
plot(car_name)
picture(car_name)
plot(cars)
str(cars)
version(R)
version
R.version
load("~/R/.RData")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
install.packages(c("askpass", "broom", "bslib", "cachem", "CCA", "checkmate", "classInt", "cli", "clue", "coin", "cpp11", "curl", "dbplyr", "deldir", "DescTools", "deSolve", "digest", "dplyr", "DT", "ellipse", "emmeans", "evaluate", "fastmap", "fda", "fields", "fontawesome", "forecast", "foreign", "fs", "gargle", "gdata", "ggbeeswarm", "ggplot2", "googledrive", "googlesheets4", "gss", "gtable", "haven", "heplots", "Hmisc", "htmltools", "httr", "hunspell", "insight", "intervals", "jsonlite", "knitr", "ks", "labeling", "later", "libcoin", "lme4", "lmom", "locfit", "lpSolve", "lubridate", "lwgeom", "magick", "magrittr", "maptools", "markdown", "MASS", "MatrixModels", "matrixStats", "mice", "minqa", "multcomp", "mvtnorm", "nnet", "nnls", "openssl", "packrat", "pkgload", "plotly", "plyr", "prettyunits", "pROC", "processx", "profvis", "promises", "ps", "psych", "purrr", "quantmod", "quantreg", "rbibutils", "Rcpp", "RcppArmadillo", "Rdpack", "readxl", "rematch", "remotes", "rgeos", "rgl", "rio", "rlang", "rmarkdown", "rootSolve", "rsconnect", "rstudioapi", "s2", "sass", "scatterplot3d", "sf", "sp", "splancs", "stars", "stringi", "survey", "survival", "sys", "testthat", "TH.data", "timeSeries", "tinytex", "tseries", "tzdb", "units", "uuid", "vctrs", "vdiffr", "VGAM", "viridis", "viridisLite", "vroom", "waldo", "webshot", "withr", "wk", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages(c("boot", "class", "cluster", "codetools", "foreign", "KernSmooth", "lattice", "MASS", "Matrix", "mgcv", "nlme", "nnet", "rpart", "spatial", "survival"), lib="C:/Program Files/R/R-4.1.2/library")
install.packages(c("askpass", "broom", "bslib", "cachem", "CCA", "checkmate", "classInt", "cli", "clue", "coin", "covr", "curl", "dbplyr", "deldir", "DescTools", "deSolve", "digest", "dotCall64", "dplyr", "DT", "emmeans", "FactoMineR", "fansi", "fastmap", "fBasics", "fda", "fields", "forecast", "foreign", "fs", "gargle", "gdata", "ggbeeswarm", "ggplot2", "ggrepel", "glmnet", "googledrive", "googlesheets4", "gss", "gtable", "haven", "heplots", "Hmisc", "htmltools", "httpuv", "hunspell", "insight", "intervals", "jsonlite", "ks", "later", "libcoin", "lme4", "lmom", "locfit", "lpSolve", "lubridate", "lwgeom", "magick", "markdown", "MASS", "Matrix", "MatrixModels", "matrixStats", "mice", "minqa", "mvtnorm", "nnet", "nnls", "openssl", "pan", "plotly", "plyr", "pROC", "processx", "profvis", "promises", "psych", "purrr", "quantmod", "quantreg", "ragg", "rbibutils", "Rcpp", "RcppArmadillo", "readxl", "rgl", "rlang", "rootSolve", "s2", "sass", "sf", "sp", "splancs", "stars", "survival", "svglite", "sys", "systemfonts", "testthat", "textshaping", "tinytex", "tseries", "tzdb", "ucminf", "units", "uuid", "vctrs", "vdiffr", "VGAM", "viridis", "vroom", "waldo", "wk", "xfun", "xml2", "yaml"))
exit
quit
knitr::opts_chunk$set(echo = TRUE)
# Centrar las distancias
distancias_centradas <- distancias - rowMeans(distancias)
# Importar los datos
distancias <- matrix(c(
0, 569, 667, 530, 141, 140, 357, 396, 570, 190,
569, 0, 1212, 1043, 617, 446, 325, 423, 787, 648,
667, 1212, 0, 201, 596, 768, 923, 882, 714, 714,
530, 1043, 201, 0, 431, 608, 740, 690, 516, 622,
141, 617, 596, 431, 0, 177, 340, 337, 436, 320,
140, 446, 768, 608, 177, 0, 218, 272, 519, 302,
357, 325, 923, 740, 340, 218, 0, 114, 472, 514,
396, 423, 882, 690, 337, 272, 114, 0, 364, 573,
569, 787, 714, 516, 436, 519, 472, 364, 0, 755,
190, 648, 714, 622, 320, 302, 514, 573, 755, 0
), nrow = 10, ncol = 10, byrow = TRUE)
# Centrar las distancias
distancias_centradas <- distancias - rowMeans(distancias)
# Calcular los vectores propios de la matriz de productos escalares centrada
eigen <- eigen(distancias_centradas)
# Obtener los vectores propios normalizados
eigen_vectores_normalizados <- eigen$vectors / sqrt(eigen$values)
# Vectores propios normalizados
eigen_vectores_normalizados
json1 = content(homeTL)
install.packages("bigrquery")
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/24-25/TFM")
setwd("C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/24-25/TFM")
library(openxlsx)
library(tidyverse)
library(lubridate)
library(summarytools)
ruta_salida2 <- "~/data/datos_filtrados.rds"
# Cargar los datos guardados
datos_importados_rds <- readRDS(ruta_salida2)
knitr::opts_chunk$set(echo = TRUE)
library(openxlsx)
library(tidyverse)
library(lubridate)
ruta_carpeta <- "~/data/"
# Obtener una lista de todos los archivos CSV en la carpeta
archivos_csv <- list.files(path = ruta_carpeta, pattern = "\\.csv$")
leer_y_filtrar <- function(archivo) {
ruta_completa <- file.path(ruta_carpeta, archivo)
read_csv(ruta_completa, col_names = TRUE) %>%
select(rideable_type, started_at, ended_at, start_station_name, end_station_name, member_casual) %>%
filter(start_station_name %in% c("Central Park S & 6 Ave",
"E 41 St & Madison Ave (SE corner)",
"Liberty St & Nassau St",
"W 116 St & Amsterdam Ave",
"Mercer St & Spring St"))
}
# Aplicar la función a cada archivo y combinar los resultados
datos_filtrados <- map_df(archivos_csv, leer_y_filtrar)
# Mostrar los primeros registros para verificar
head(datos_filtrados)
getwd()
knitr::opts_chunk$set(echo = TRUE)
plot1<-ggplot(data=datos_importados_rds, mapping = aes(x=fecha_ride, y = after_stat(count))) +
geom_freqpoly(size=1) +
theme(axis.text.x=element_text(angle = 30, hjust = 1)) +
scale_x_date(breaks = "1 month", expand = c(0, 0),limits = as.Date(c("2022-10-31","2024-11-01")))
knitr::opts_chunk$set(echo = TRUE)
library(openxlsx)
library(tidyverse)
library(lubridate)
library(summarytools)
#start_time <- Sys.time()
#end_time <- Sys.time()
#time_taken <- end_time - start_time
#print(time_taken)
# Leer el archivo RDS
ruta_salida2 <- "C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/24-25/TFM/data/datos_filtrados2.rds"
# Cargar los datos guardados
datos_importados_rds <- readRDS(ruta_salida2)
str(datos_importados_rds)
#comprobar que el file leido es identico a generado antes
#identical(datos_filtrados2, datos_importados_rds)
#citibike_2324<-data.frame(datos_importados_rds)
## Generar un resumen del conjunto de datos del tren
#dfSummary(datos_importados_rds, plain.ascii = FALSE, style = "grid")
library(summarytools)
library(knitr)
#dfSummary(datos_importados_rds, plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
datos_importados_rds_sum_tbl <- datos_importados_rds %>%
dfSummary(plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
datos_importados_rds_sum_tbl%>%
select(-text.graph) %>%
knitr::kable(align = "c")
## Generar un resumen del conjunto de datos del tren
#dfSummary(datos_importados_rds, plain.ascii = FALSE, style = "grid")
library(summarytools)
library(knitr)
#dfSummary(datos_importados_rds, plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
datos_importados_rds_sum_tbl <- datos_importados_rds %>%
dfSummary(plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
datos_importados_rds_sum_tbl%>%
select(-text.graph) %>%
knitr::kable(align = "c")
## Generar un resumen del conjunto de datos del tren
#dfSummary(datos_importados_rds, plain.ascii = FALSE, style = "grid")
library(summarytools)
library(knitr)
#Evaluation cases out range
dur_negativa <- subset(datos_importados_rds, duracion_min < 0)
fechas_fuera <- subset(datos_importados_rds, fecha_ride < '2022-11-01')
#adjustments by imputation values
datos_importados_rds$duracion_min[datos_importados_rds$duracion_min < 0]<-0
datos_importados_rds$fecha_ride[datos_importados_rds$fecha_ride<'2022-11-01']<-'2022-11-01'
datos_importados_rds$started_at[datos_importados_rds$started_at<'2022-11-01']<-'2022-11-01'
# after Results
datos_importados_rds_sum_tbl <- datos_importados_rds %>%
dfSummary(plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
datos_importados_rds_sum_tbl%>%
select(-text.graph) %>%
knitr::kable(align = "c")
plot1<-ggplot(data=datos_importados_rds, mapping = aes(x=fecha_ride, y = after_stat(count))) +
geom_freqpoly(size=1) +
theme(axis.text.x=element_text(angle = 30, hjust = 1)) +
scale_x_date(breaks = "1 month", expand = c(0, 0),limits = as.Date(c("2022-10-31","2024-11-01")))
plot1
plot2 <- datos_importados_rds %>% ggplot(aes(member_casual, fill = member_casual)) %+% geom_bar(position = "dodge")
plot2
plot3 <- datos_importados_rds %>% ggplot(aes(start_station_name, fill = start_station_name)) %+% geom_bar(position = "dodge") %+%
theme(axis.text.x=element_text(angle = 30, hjust = 1))
plot3
plot4 <- datos_importados_rds %>% ggplot(aes(rideable_type, fill = rideable_type)) %+% geom_bar(position = "dodge") %+%
theme(axis.text.x=element_text(angle = 30, hjust = 1))
plot4
plot5 <-
ggplot(datos_importados_rds, aes(member_casual,duracion_min)) +
geom_boxplot(aes(colour = member_casual))
plot5
plot6 <-
ggplot(datos_importados_rds, aes(start_station_name,duracion_min)) +
geom_boxplot(aes(colour = start_station_name))
plot6
plot7 <-
ggplot(datos_importados_rds, aes(rideable_type,duracion_min)) +
geom_boxplot(aes(colour = rideable_type))
plot7
plot11<-ggplot(data=datos_importados_rds, mapping = aes(x=fecha_ride, y = after_stat(count))) +
geom_freqpoly(size=1,mapping = aes(colour = member_casual)) +
theme(axis.text.x=element_text(angle = 30, hjust = 1)) +
scale_x_date(breaks = "1 month", expand = c(0, 0),limits = as.Date(c("2022-10-31","2024-11-01")))
plot11
plot12<-ggplot(data=datos_importados_rds, mapping = aes(x=fecha_ride, y = after_stat(count))) +
geom_freqpoly(size=1,mapping = aes(colour = start_station_name)) +
theme(axis.text.x=element_text(angle = 30, hjust = 1)) +
scale_x_date(breaks = "1 month", expand = c(0, 0),limits = as.Date(c("2022-10-31","2024-11-01")))
plot12
plot13<-ggplot(data=datos_importados_rds, mapping = aes(x=fecha_ride, y = after_stat(count))) +
geom_freqpoly(size=1,mapping = aes(colour = rideable_type)) +
theme(axis.text.x=element_text(angle = 30, hjust = 1)) +
scale_x_date(breaks = "1 month", expand = c(0, 0),limits = as.Date(c("2022-10-31","2024-11-01")))
plot13
library(gridExtra)
grid.arrange(plot1, plot2, plot3,plot4,plot5,plot6,plot7,plot11, plot12,plot13, ncol = 2)
version(summarytools)
knitr::opts_chunk$set(echo = TRUE)
#library(openxlsx)
library(tidyverse)
library(lubridate)
# Leer el archivo RDS
ruta_salida2 <- "C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/24-25/TFM/data/datos_filtrados2.rds"
# Cargar los datos guardados
datos_importados_rds <- readRDS(ruta_salida2)
str(datos_importados_rds)
#library(openxlsx)
#library(tidyverse)
#library(lubridate)
# Leer el archivo RDS
ruta_salida2 <- "C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/24-25/TFM/data/datos_filtrados2.rds"
# Cargar los datos guardados
datos_importados_rds <- readRDS(ruta_salida2)
str(datos_importados_rds)
## Generar un resumen del conjunto de datos del tren
library(summarytools)
#library(knitr)
#dfSummary(datos_importados_rds, plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
datos_importados_rds_sum_tbl <- datos_importados_rds %>%
dfSummary(plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
datos_importados_rds_sum_tbl%>%
select(-text.graph) %>%
knitr::kable(align = "c")
packageVersion('summarytools')
datos_importados_rds_sum_tbl <- datos_importados_rds %>%
dfSummary(plain.ascii = FALSE, style = "grid", graph.magnif = 0.75, method="render")
packageVersion('R')
r.version
R.version
version.package("knirt")
version.package("knitr")
packageVersion('Knitr')
packageVersion('ggplot2')
packageVersion('gridextra')
tost_razon_medias <- function(n1, media1, sd1, n2, media2, sd2, deltaL)
{
deltaU <- 1 / deltaL
varcomun <- ((n1 - 1) * sd1^2 + (n2 - 1) * sd2^2) / (n1 + n2 - 2)
sdcomun <- sqrt(varcomun)
gradoslib <- n1 + n2 - 2
ta <- (media2 - media1 * deltaL) / (sdcomun * sqrt((deltaL^2 / n1) + (1 / n2)))
valor_p1 <-  1 - pt(abs(ta), gradoslib)
tb <- (media2 - media1 * deltaU) / (sdcomun * sqrt((deltaU^2 / n1) + (1 / n2)))
valor_p2 <- 1 - pt(abs(tb), gradoslib)
cat("\n")
cat("\n")
cat("Test de equivalencia para la razon de dos medias \n")
cat("\n")
cat("  DeltaL: ", deltaL, "\n")
cat("\n")
cat("  DeltaU: ", deltaU, "\n")
cat("\n")
cat("Test A. Ho: mu2 / mu1 <= DeltaL  \n")
cat("\n")
cat("  Estadistico de contraste: ", round(ta, 4), "\n")
cat("\n")
cat("  Valor-P: ", round(valor_p1, 4), "\n")
cat("\n")
cat("Test B. Ho: mu2 / mu1 >= DeltaU  \n")
cat("\n")
cat("  Estadistico de contraste: ", round(tb, 4), "\n")
cat("\n")
cat("  Valor-P: ", round(valor_p2, 4), "\n")
cat("\n")
cat("Valor-P del test de equivalencia: ", round(max(valor_p1, valor_p2), 4), "\n")
cat("\n")
}
tost_razon_medias(15,78.45,4.25,15,76.15,4.12,0.8)
library(pROC)
load("~/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/24-25/Bioestadistica/24-25/Tema 7/hsa.RData")
View(hsa)
View(hsa)
View(hsa)
roc1 <- roc(hsa$pronos, hsa$test1)
roc1
roc2
roc2 <- roc(hsa$pronos, hsa$test2)
roc2
plot.roc(roc1, legacy.axes = TRUE, xlim= c(1,0))
plot.roc(roc2, legacy.axes = TRUE, xlim= c(1,0))
> ci.auc(roc1)
ci.auc(roc1)
ci.auc(roc2)
roc1 <- roc(hsa$pronos, hsa$test1)
roc1
plot.roc(roc1, legacy.axes = TRUE, xlim= c(1,0))
ci.auc(roc1)
plot.roc(roc1, legacy.axes = TRUE, xlim= c(1,0), col = "blue")
plot(roc2, add=TRUE, col = "red")
roc.test(roc1, roc2, method="venkatraman")
version()
rversion()
getRversion()
sessionInfo()
library(tidyverse)
library(lubridate)
setwd('C:/Users/franm/OneDrive/Documents/Personales/Javier/Academicos/UGR - Estadistica Aplicada/Materias/24-25/TFM')
getwd()
nycweather<-read.csv('data/NYC weather 2022-2024.csv')
str(nycweather)
